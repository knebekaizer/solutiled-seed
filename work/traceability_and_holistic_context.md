Traceability and holistic context
---------------------------------

**Disclaimer**. Ниже много букв  и тривиальное решение: a) любое решение - тривиальное, когда высказано b) почему-то оно нигде у нас не реализовано, хотя бонусов - куча. Много букв - потому что я описываю не совсем очевидные применения для очень простой машинерии.

Суть этого текста - архитектурное предложение: как организовать логгирование для целей отладки и аналитики в ситуации, когда asynch control flow является основным паттерном, а само приложение - клиент-сервер, микросервисы, кластер или просто local multithreaded app с кучей эвент лупов.

Log о котором я здесь говорю может иметь разный вид, от обычного тестового лога, a la log4J до таблицы эвентов в БД или event sourcing для продвинутых.

Слово "холистический" сюда приехало из аналитики и биг даты, где есть понятие "holistic profile", это такой всесторонний набор данных, который позволяет анализировать поведение клиента в разных аспектах.

Сначала - два примера существующих проблем.

1. Пример первый: Аналитика, big data. Приложение логгирует события,  нтересные для аналитики. Например в клиентском приложении: юзер что-то сделал, тапнул по экрану и т.п. Или (серверное событие) деньги (виртуальная валюта) перевели с одного счета на другой, юзер получил новые плюшки, перешел на следующий уровень, и т.п. Аналитик изучает эти события, чтобы предсказывать поведение и манипулировать юзером в нужную сторону. Для анализа нужен **контекст** события. Лобовое решение: аналитик говорит: "для анализа надо знать, к каой когорте принадлежит юзер, у которого случилось это событие. И ещё - какой у него цвет глаз" => разработчик бежит фиксить приложение: чтобы записать в лог id когорты, он должен в данной функции добыть user id, сходить с ним в API или в БД, накостылять пару глобальных переменных для этого и т.д. И выкатить патч в поле, хорошо если немного протестит перед этим ("это же не продуктовая фича").

2. Пример второй. Отладка, self-healing application и полевой health monitoring. Положительные герои умеют пользоваться ассертами:  "use assertions to ensure contract: pre-, post-condition and invariants". Щедро напиханные умелыми руками ассерты сказочно упрощают жизнь будущих мэйнтейнеров. Но у ассертов есть ограничение: здесь и сейчас можно проверить только **локальный инвариант**. Если я напишу `assert(a == b + c)`, то все три a,b,c должны быть доступны в этом месте кода (capturing не предлагать...). Это сильно связывает, или заставляет костылять ("я тут добавил глобальную переменную, но только в DEBUG"). Еще одно похожее рахочарование: пусть я умею собирать полевые крэш дампы, это круто... но я часто вижу унылую картину: крэш на эвент хандлере, это первый вызов на нитке, стек пустой и всё что есть - это три параметра, которые приехали в эвенте, а хотелось бы знать предысторию control flow, откуда этот эвент взялся.

**Решение**. Провяжем наш async flow одной чиселкой, uniq id. Назову его `flow_id`. Я буду передаввать эту чиселку через API, эвенты и параметры async call. В интересных местах в любом процессе и нитке я логгирую этот `flow_id` и доступный в данном месте кода local context (например, аргументы данной функции). В пост-процессинге, когда-нибудь потом (не в поле и не в продуктовом коде), я грепну лог по конкретному значению flow_id (ELK, конечно) и соберу (merge) все отдельно взятые локальные контексты в большую структуру: глобальный (холистический) контекст данного конкретного флоу. Например, если мне нужен цвет глаз, я поднимусь по цепочке до того места, где произошла авторизация (REST конечно), а там есть токен, по которому можно раскрутить user id и детали профиля юзера. Весь этот наворот - не в продуктовом коде!

**Что такое flow id?** В нашей асинхронной системе есть точки начала каждого control flow. Они бывают двух сортов: волюнтаристские действия юзера (жмакнул кнопку) и внешние события (сработал тайиер, или фейсбучный друг прислал подарок, и т.п.) Для обработки конкретного события разработчик написал функцию, handler. Когда разработчик накодил новый хэндлер - он **создал** новый тип того, что мы назовём триггером и присвоил ему новый уникальный `flow_type_id`. Когда в рантайме этат хэндлер сработал - он запустил (triggered) новый флоу. В этот момент сгенерим новый `flow_id` (на каждое срабатывание триггера). Пара `(flow_type, flow_id)` представляет из себя уникальный `trigger_id`, который я и буду грепать в логе.

Flow конечный, и грепнутая цепочка конечная - я могу подняться по ней только до триггера. В этот момент цепочка прерывается. Но иногда я хочу подняться по истории дальше. Для этого первое событие цепочки (триггер) содержит информацию, которая позволяет связать его с предысторией. Например, сработал таймер: я пишу в лог новый `trigger_id` _и timer id_ сработавшего таймера (здесь это локальный контекст). Потом я могу найти в логе тот же timer id (событие, когда таймер взвели) и раскрутить флоу, который является логической первопричиной. Такое может понадобиться для сложной отладки.


**Профит:**

- Separation of concerncs. Разработчику не надо напрягать мозг, пыаясь находиться одновременно в разных проблемных областях. Любой джун в силах тупо залоггировать три переменных, которые составляют локальный контекст его функции. Нагружать семантикой, смыслом эти переменные будет человек из другого домена. Причем даже для одного потребителя (например аналитика) эта семантика может меняться сегодня и завтра, а зависимости от алгоритма, в котором он решил заюзать данную переменную как атрибут некоторой сущности. Еще один "потребитель лога" - QA или GD, который, исходя из геймдизайна понял, что имеет место важный инвариант в бизнес-логике, но разные части этого инварианта доступны в разных местах кода. Теперь, вместо того, чтобы калечить код, можно написать post-processing validator и гонять его на логе "почти в реалтайме". Это аналог ассерта, но не локальный, а глобальный (холистический). Повторю, это суперважно: это high level инвариант (ассерт), он находится в бизнес-логике, business domain. Не разрывайте мозг простому кодеру ненужным ему знанием верхнеуровневой бизнес-логики (такое понимание не опускается ниже архитектора и не доходит до кодеров, и не нужно).

- Stable production code. Вся вариативность уехала в пост-процессинг, который не требует такого тестирования, его можно патчить и деплоить каждуе пять минут, и можно иметь одновременно 100500 запущенных разных версий пост-процессинговых скриптов.

- Health monitoring. Я могу крутить валидатор на логе next to real-time, с минимальной задержкой. Можем кидать алерт разработчикам, что в поле беда, до того как юзеры что-то заметили. (Помечтаем) Можно в реал-тайме грохнуть текущий flow на основании автоматического алерта до того, как юзер сольёт свои деньги в результате софтовой баги. Повторю: разработчик не смог бы написать такой ассерт, потому что он 1) нелокальный 2) вне пределов его компетенции.

**Формат и процесс**. Каждый разработчик в местах, которые ему кажутся интересными, механически логгирует текущий контекст в надежде, что он кому-то понадобится. Это serializer, для расшифровки понадобится десериализовать и присвоить семантический смысл. Нужен очень гибкий формат serialize/deserialize + reflection. Например JSON. Строка просто уходит в ELK или в кассандру. Залоггировать такую строчку - не требует интеллекта и знания бизнес-логики. Логгировать можно все подряд, не заморачиваясь документированием смысла этих переменных. Когда аналитику понадобился, например, текущий уровень игрока - он придет к лиду разработки и скажет: "я грепнул цепочку эвентов, вот она, где-то в этой цепочке есть текущий уровень - покажи, где". Лид в данном случае служит переводчиком, связывает две проблемных области, разработку и бизнес-аналитику. Прелесть в том, что a) заморачиваться переводом надо не чаще, чем возникает вопрос у потребителя, а один-два аналитика не сгенерят непомерный список вопросов b) Эта операция, декодирование и присваивание семантики - целиком в постпроцессинге. В продукте - только механическая отгрузка локального контекста события, и эта часть меняется не чаще, чем появляется новая фича или рефакторится код.

**Теорема существования** Искомый атрибут обязательно найдется в цепочке флоу, если известно, что этот атрибут участвует в бизнес-логике. Возможно, нужную функцию пропустили и не залоггировали, но по крайней мере искомый атрибут является локально доступной переменной в одной из функций данного флоу - а именно, там где его применили в бизнес-логике. Добавьте лог именно в этом месте.

**Legacy**. Такую схему удобно реализовать в новом коде. Но и в легаси можно затащить, постепенно. Нет нужды трабовать, чтобы все API были провязаны сразу. Можно добавить trigger id в один только флоу, и залоггировать только в некоторых функциях, на основании того, что нужно аналитику и QA прямо сейчас. Когда аналитик поймет, что ему чего-то не хватает, он придет и скажет: "Слушай, тут контекст получился недостаточно холистический))). Мне еще нужна фаза луны. Ты тут новичок, джун, и не знаешь об этом, но я уверен, что в твоём флоу где-то должна быть функция, в которой доступна такая инфа, потому что по бизнес-логике решение принимается с учетом погоды и фазы луны. Найди это место во флоу и лобавь в логгирование, пожалуйста". Чтобы начать применять схему, достаточно договориться о формате trigger id, и сохранить легаси лог наряду с появлением нового формата. Вместо того, чтобы фиксить или поддерживать существующий выхлоп, для каждого фикса или импрува будем добавлять запсись в новом формате.

**Альтернатива тестированию**. Отказ от ручного тестирования - это мировой тренд. Приложение с неограниченным континуальным множеством сценариев вообще не может быть покрыто предрелизными сценарными тестами. Тем более - ручными. Пример -  RPG, multiplayer, etc. Кто куда двинулся и какие при этом случились временнЫе задержки и где у меня вылезет бага, race condition... Это невозможно смоделировать в тестировании. Значит, нужен другой подход: собираем быстрый фидбек с поля или из триала, умеем очень быстро найти причину и зафиксить, и оченть быстро выкатить фикс (быстро поднятое упавшим не считается). Таким образом, quality assurance смещается с предрелизного тестирования в полевой health monitoring, средства анализа и continious delivery. Для тестирования остается sanity, да и тот будет вытесняться автоматическим POST (power-on self-test) в сочетании с canary deployment. 

**Out of scope**. Можно долго говорить об уровнях логгирования, compile time / run-time, как с сервера динамически управлять уровнем логгирования на время и для конкретного юзера (или группы) или в конкретном модуле, etc. 
